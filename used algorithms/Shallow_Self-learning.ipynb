{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf5bQw9lZTzN"
   },
   "source": [
    "# Bachelor's thesis: Shallow Self-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The corresponding paper is: Kozodoi, Nikita, et al. \"Shallow self-learning for reject inference in credit scoring.\" Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2019, Würzburg, Germany, September 16–20, 2019, Proceedings, Part III. Springer International Publishing, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepts = pd.DataFrame()\n",
    "accepts = pd.read_csv('../data/New_accepts.csv',encoding = \"ISO-8859-1\", low_memory=False)\n",
    "rejects = pd.DataFrame()\n",
    "rejects = pd.read_csv('../data/New_rejects.csv',encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc = accepts.copy()\n",
    "X_rej = rejects.copy()\n",
    "y_rej = X_rej.pop(\"loan_status\")\n",
    "y_acc = X_acc.pop(\"loan_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I store a reference dataframe, because I compare this reference with the true outcomes to my predicted probability of default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(X_acc[['loan_amnt', 'emp_length', 'dti', 'fico']])\n",
    "X_acc[['loan_amnt', 'emp_length', 'dti', 'fico']] = scaler.transform(X_acc[['loan_amnt', 'emp_length', 'dti', 'fico']])\n",
    "X_rej[['loan_amnt', 'emp_length', 'dti', 'fico']] = scaler.transform(X_rej[['loan_amnt', 'emp_length', 'dti', 'fico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc = pd.get_dummies(data=X_acc, columns = ['addr_state'], drop_first = True)\n",
    "X_rej = pd.get_dummies(data=X_rej, columns = ['addr_state'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_acc[['loan_amnt', 'emp_length', 'dti', 'fico']])\n",
    "X_acc[['loan_amnt', 'emp_length', 'dti', 'fico']] = scaler.transform(X_acc[['loan_amnt', 'emp_length', 'dti', 'fico']])\n",
    "X_rej[['loan_amnt', 'emp_length', 'dti', 'fico']] = scaler.transform(X_rej[['loan_amnt', 'emp_length', 'dti', 'fico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepts_reference = np.column_stack([X_acc, y_acc])\n",
    "accepts_reference = pd.DataFrame(accepts_reference)\n",
    "rejects_reference = np.column_stack([X_rej, y_rej])\n",
    "rejects_reference = pd.DataFrame(rejects_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepts_reference.columns = ['loan_amnt', 'emp_length', 'dti', 'fico','addr_state_1',\"addr_state_2\",\"addr_state_3\",'loan_status']\n",
    "rejects_reference.columns = ['loan_amnt', 'emp_length', 'dti', 'fico','addr_state_1',\"addr_state_2\",\"addr_state_3\",'loan_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Self-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First you can include the Isolation Forest to filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isolation_forest = IsolationForest(random_state=42)\n",
    "isolation_forest.fit(X_rej)\n",
    "scores = isolation_forest.decision_function(X_rej)\n",
    "b_top = np.percentile(scores, 0)  # Adjust percentile as required\n",
    "b_bot = np.percentile(scores, 100)\n",
    "\n",
    "Xr = (X_rej[scores > b_top] | X_rej[scores < b_bot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also need to set up a list to append the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_probas = y_acc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_star = X_rej.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the parameters to tune. Alpha is the labeled percentage of rejects which are sampled per loop. Theta is the imbalance parameter, max_iteration is how often the algorithm samples rejects and you can set the penalty parameter for the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "theta = 1 \n",
    "max_iteration = 5\n",
    "penalty_parameter = 2**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "while (len(X_star) > 0 and max_iteration >= 0):\n",
    "\n",
    "    \n",
    "    # Train Logistic Regression in all data in X_star\n",
    "    \n",
    "    model = LogisticRegression(C = penalty_parameter, solver='liblinear', random_state=42)\n",
    "    model.fit(X_acc, y_acc)\n",
    "    y_rejected_pred = model.predict_proba(X_star)[:, 1]\n",
    "\n",
    "    \n",
    "    # Establish the parameters and caluclate thresholds for appending\n",
    "    \n",
    "    # Define as per your requirements\n",
    "    # Imbalance parameter\n",
    "    \n",
    "    cg = np.percentile(y_rejected_pred, alpha * 100)\n",
    "    cb = np.percentile(y_rejected_pred, (1 - alpha * theta) * 100)\n",
    "    \n",
    "    # Select the filtered observations by the thresholds\n",
    "    \n",
    "    selected_indices = (y_rejected_pred <= cg) | (y_rejected_pred >= cb)\n",
    "    X_selected = X_star[selected_indices]\n",
    "    y_selected_probs = (y_rejected_pred[selected_indices])\n",
    "    y_selected = [int(i >= cg) for i in y_selected_probs]\n",
    "        \n",
    "    # If there are no selected observations break\n",
    "\n",
    "    if len(y_selected) == 0:\n",
    "        print(\"Stopping criterion met: No new samples exceed the thresholds.\")\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Remove observations from X_star and append them to X_acc and their inferred labels to y_acc for further model training in the next steps\n",
    "\n",
    "    X_star = X_star[~selected_indices] \n",
    "    X_acc = np.vstack([X_acc, X_selected])\n",
    "    y_acc = np.concatenate([y_acc, y_selected])\n",
    "    Pred_probas = np.concatenate([Pred_probas, y_selected_probs])\n",
    "\n",
    "    max_iteration = max_iteration-1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I create my unbiased set with the inferred labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted = np.column_stack([X_acc, Pred_probas])\n",
    "data_predicted = pd.DataFrame(data_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted.columns = ['loan_amnt', 'emp_length', 'dti', 'fico','addr_state_1',\"addr_state_2\",\"addr_state_3\",'loan_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then I map my rejects with the predicted labels to the true labels. You can also merge on the accepts and it will show perfect metrics because we know the true labels of the accepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in accepts_reference.columns if col != 'loan_status']\n",
    "\n",
    "# Zusammenführen der beiden DataFrames auf Basis der Schlüsselspalten\n",
    "comparison = data_predicted.merge(\n",
    "    rejects_reference, \n",
    "    on=columns, \n",
    "    suffixes=('_pred', '_true'), \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Vergleich der Vergleichsspalte\n",
    "#vergleich_df['Vergleich_stimmt'] = vergleich_df['loan_status_klein'] == vergleich_df['loan_status_gross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison['loan_status_true'] = comparison['loan_status_true'].astype(float)\n",
    "comparison['loan_status_pred'] = comparison['loan_status_pred'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5839945963124618\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(comparison['loan_status_true'], comparison['loan_status_pred'])\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.3520623601650927\n"
     ]
    }
   ],
   "source": [
    "brier = brier_score_loss(comparison['loan_status_true'], comparison['loan_status_pred'],pos_label=1)\n",
    "print(\"Brier score:\", brier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS-Statistic: 0.16931435210878132\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(comparison['loan_status_true'], comparison['loan_status_pred']) \n",
    "ks_statistic = max(tpr - fpr)\n",
    "print(\"KS-Statistic:\",ks_statistic)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_ex_data_prep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
