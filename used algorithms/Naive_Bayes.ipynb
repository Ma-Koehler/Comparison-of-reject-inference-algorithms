{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf5bQw9lZTzN"
   },
   "source": [
    "# Bachelor's thesis: Naive Bayes EM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The corresponding paper is: Anderson, Billie. \"Naive Bayes using the expectation-maximization algorithm for reject inference.\" Communications in Statistics: Case Studies, Data Analysis and Applications 8.3 (2022): 484-504."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden von Standard-Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, brier_score_loss\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf5bQw9lZTzN"
   },
   "source": [
    "## Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepts = pd.DataFrame()\n",
    "accepts = pd.read_csv('../data/New_accepts.csv',encoding = \"ISO-8859-1\", low_memory=False)\n",
    "rejects = pd.DataFrame()\n",
    "rejects = pd.read_csv('../data/New_rejects.csv',encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc = accepts.copy()\n",
    "X_rej = rejects.copy()\n",
    "y_rej = X_rej.pop(\"loan_status\")\n",
    "y_acc = X_acc.pop(\"loan_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We preprocess the data as per the paper with 4 bins per feature and accepts and rejects binned seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_emp_length(x):\n",
    "    if(x== 0):\n",
    "        return 0\n",
    "    if(x== 1 or x== 2 or x== 3 or x== 4 or x == 5):\n",
    "        return 1\n",
    "    if(x==6 or x== 7 or x== 8 or x== 9):\n",
    "        return 2\n",
    "    if(x== 10):\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc['emp_length'] = X_acc['emp_length'].apply(categorize_emp_length)\n",
    "X_rej['emp_length'] = X_rej['emp_length'].apply(categorize_emp_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc['loan_amnt'] = pd.qcut(X_acc['loan_amnt'], 4, labels=False)\n",
    "X_acc['dti'] = pd.qcut(X_acc['dti'], 4, labels=False)\n",
    "X_acc['fico'] = pd.qcut(X_acc['fico'], 4, labels=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rej['loan_amnt'] = pd.qcut(X_rej['loan_amnt'], 4, labels=False)\n",
    "X_rej['dti'] = pd.qcut(X_rej['dti'], 4, labels=False)\n",
    "X_rej['fico'] = pd.qcut(X_rej['fico'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc['loan_amnt'] = X_acc['loan_amnt'].astype('category')\n",
    "X_acc['dti'] = X_acc['dti'].astype('category')\n",
    "X_acc['fico']= X_acc['fico'].astype('category')\n",
    "X_acc['emp_length']= X_acc['emp_length'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rej['loan_amnt'] = X_rej['loan_amnt'].astype('category')\n",
    "X_rej['dti'] = X_rej['dti'].astype('category')\n",
    "X_rej['fico']= X_rej['fico'].astype('category')\n",
    "X_rej['emp_length']= X_rej['emp_length'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acc = pd.get_dummies(data=X_acc, columns = ['loan_amnt'], drop_first = False)\n",
    "X_acc = pd.get_dummies(data=X_acc, columns = ['dti'], drop_first = False)\n",
    "X_acc = pd.get_dummies(data=X_acc, columns = ['fico'], drop_first = False)\n",
    "X_acc = pd.get_dummies(data=X_acc, columns = ['emp_length'], drop_first = False)\n",
    "X_acc = pd.get_dummies(data=X_acc, columns = ['addr_state'], drop_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rej = pd.get_dummies(data=X_rej, columns = ['loan_amnt'], drop_first = False)\n",
    "X_rej = pd.get_dummies(data=X_rej, columns = ['dti'], drop_first = False)\n",
    "X_rej = pd.get_dummies(data=X_rej, columns = ['fico'], drop_first = False)\n",
    "X_rej = pd.get_dummies(data=X_rej, columns = ['emp_length'], drop_first = False)\n",
    "X_rej = pd.get_dummies(data=X_rej, columns = ['addr_state'], drop_first = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also need to set up a list for the parameters. Those are the estimated thetas, variances and prior class probabilities which we will average over the bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_estimates_theta = []\n",
    "parameter_estimates_var = []\n",
    "parameter_estimates_class_prior = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here you can chose the parameters, which are the fraction of accepts and rejects used in the Bootstrapping. The paper suggested 1/4 of the accepts and 1/6 of the rejects. We also need to set the value for the amount of Bootstraps we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_accepts = 1/6\n",
    "fraction_rejects = 1/4\n",
    "Bootstrap = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping to obtain parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(Bootstrap):\n",
    "            \n",
    "            \n",
    "    #1. Data Preprocessing\n",
    "            \n",
    "    accept = pd.concat([X_acc, y_acc], axis = 1)\n",
    "    accept_sampled = accept.sample(frac = fraction_accepts, replace = True)\n",
    "    reject_sampled = X_rej.sample(frac = fraction_rejects, replace = True)\n",
    "    y_acc_sampled = accept_sampled.pop(\"loan_status\") \n",
    "            \n",
    "    #2. Build Naive Bayes model using accepted data\n",
    "            \n",
    "    first_model = GaussianNB()\n",
    "            \n",
    "    first_model.fit(accept_sampled, y_acc_sampled)\n",
    "\n",
    "    #3. Predict labels for rejected applicants\n",
    "\n",
    "    y_rejected_pred = first_model.predict_proba(reject_sampled)\n",
    "    y_rejected_pred = y_rejected_pred[:,1]\n",
    "    y_rejected_pred = [int(i >= 0.5) for i in y_rejected_pred]\n",
    "\n",
    "    #4. Build a new model using accepts and rejects with inferred labels\n",
    "\n",
    "    second_model=GaussianNB()\n",
    "    X_combined = np.concatenate((accept_sampled, reject_sampled))\n",
    "    y_combined = np.concatenate((y_acc_sampled, y_rejected_pred))\n",
    "            \n",
    "    #print(np.shape(X_combined))\n",
    "            \n",
    "    second_model.fit(X_combined, y_combined)\n",
    "\n",
    "    #print(nb_model.theta_)\n",
    "    #print(np.shape(y_combined))\n",
    "    #print(second_model.theta_)\n",
    "    #print(second_model.var_)\n",
    "            \n",
    "    # Store parameter estimates      \n",
    "    parameter_estimates_theta.append(second_model.theta_)\n",
    "    parameter_estimates_var.append(second_model.var_)\n",
    "    parameter_estimates_class_prior.append(second_model.class_prior_)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 5 features and 4 bins per feature meaning 5 * 4 = 20 features in total. Our Bayesian model optimizes 2 parameters per feature meaning we need a list of 20 * 2. We need 2 lists for theta and variance, as well as a parameter for the prior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2, 20)\n",
    "parameter_theta = np.zeros(shape)\n",
    "parameter_var = np.zeros(shape)\n",
    "parameter_class_prior = [0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we average the estimates from the Bootstrapping procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range (2):\n",
    "    for j in range (20):\n",
    "        for i in range (Bootstrap):\n",
    "            parameter_theta[l][j] = parameter_theta[l][j] + parameter_estimates_theta[i][l][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range (2):\n",
    "    for j in range (20):\n",
    "        for i in range (Bootstrap):\n",
    "            parameter_var[l][j] = parameter_var[l][j] + parameter_estimates_var[i][l][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range (2):\n",
    "    for j in range (20):\n",
    "        parameter_theta[l][j] = parameter_theta[l][j] / (Bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range (2):\n",
    "    for j in range (20):\n",
    "        parameter_var[l][j] = parameter_var[l][j] / (Bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (2):\n",
    "    for i in range (Bootstrap):\n",
    "        parameter_class_prior[j] = parameter_class_prior[j] +  parameter_estimates_class_prior[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (2):\n",
    "    parameter_class_prior[j] = parameter_class_prior[j] / (Bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.theta_ = parameter_theta\n",
    "gnb.var_ = parameter_var\n",
    "gnb.class_count_ = np.array([459005, 93530])  \n",
    "gnb.class_prior_ = parameter_class_prior\n",
    "gnb.classes_ = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "yhat = gnb.predict_proba(X_rej)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5133459117323874\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_rej,yhat[:,1])\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.5609473127067169\n"
     ]
    }
   ],
   "source": [
    "brier = brier_score_loss(y_rej,yhat[:,1],pos_label=1)\n",
    "print(\"Brier score:\", brier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS-Statistic: 0.02350272441458101\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_rej,yhat[:,1]) \n",
    "ks_statistic = max(tpr - fpr)\n",
    "print(\"KS-Statistic:\",ks_statistic)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_ex_data_prep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
